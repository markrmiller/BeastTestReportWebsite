<!doctype html>
<html>
  <head>
    <title>HBeast Report Info</title>
  </head>
  <body>
<p><pre>On branch HBASE-23787
Your branch is ahead of 'apache/master' by 2 commits.
  (use "git push" to publish your local commits)

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

	modified:   hbase-mapreduce/src/test/resources/hbase-site.xml
	modified:   hbase-mapreduce/src/test/resources/hbase-site2.xml
	modified:   hbase-rest/src/test/resources/hbase-site.xml
	modified:   hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java
	modified:   hbase-server/src/test/java/org/apache/hadoop/hbase/master/procedure/TestMasterFailoverWithProcedures.java
	modified:   hbase-server/src/test/resources/hbase-site.xml
	modified:   hbase-server/src/test/resources/hbase-site2.xml
	modified:   hbase-thrift/src/test/resources/hbase-site.xml
	modified:   pom.xml

Untracked files:
  (use "git add <file>..." to include in what will be committed)

	beast.sh

no changes added to commit (use "git add" and/or "git commit -a")</pre><br/></br>Log -10</br><pre>commit c249821dbef2c86dc88c01d06c211ed3cd89227c
Author: Mark Miller <markrmiller@apache.org>
Date:   Wed Feb 5 21:19:57 2020 -0600

    WIP: work on 127.0.0.1

commit 6d8de9491e57f98a818bf2ff30985248d4031e0f
Author: Mark Miller <markrmiller@apache.org>
Date:   Mon Feb 3 21:01:27 2020 -0600

    HBASE-23787: TestSyncTimeRangeTracker fails quite easily and allocates a very expensive array.

commit 5b4545de5ec8380c827bf4600f4940452eaea782
Author: Nick Dimiduk <ndimiduk@apache.org>
Date:   Wed Feb 5 14:41:51 2020 -0800

    HBASE-23802 Remove unnecessary Configuration instantiation in LossyAccounting (#1127)
    
    Signed-off-by: stack <stack@apache.org>

commit b49ec5807349ab566675063b8280611aea2dd681
Author: Michael Stack <saintstack@users.noreply.github.com>
Date:   Tue Feb 4 20:47:02 2020 -0800

    HBASE-23779 Up the default fork count; make count relative to CPU count (#1108)
    
    Set the fork count for first and second parts to be 0.5C. Add a bit of
    doc too on this as well as some qualification on our test categories.
    Also adds -T0.5C to MAVEN_ARGS in the hbase personality.

commit 3a1a39d40d8a4733c5e657793eaec1c4cf40dde8
Author: stack <stack@apache.org>
Date:   Tue Feb 4 16:39:33 2020 -0800

    HBASE-23789 [Flakey Tests] ERROR [Time-limited test] balancer.HeterogeneousRegionCountCostFunction(199): cannot read rules file located at ' /tmp/hbase-balancer.rules '; ADDENDUM Missed adding these files.

commit 9cc7a711e616566ecedb8620a1c8b8a29c3d27b0
Author: stack <stack@apache.org>
Date:   Tue Feb 4 12:30:09 2020 -0800

    HBASE-23789 [Flakey Tests] ERROR [Time-limited test] balancer.HeterogeneousRegionCountCostFunction(199): cannot read rules file located at ' /tmp/hbase-balancer.rules '

commit 6ba1df3b3932ce5825cb43511a7483e64f9471f9
Author: Nick Dimiduk <ndimiduk@apache.org>
Date:   Tue Feb 4 16:04:14 2020 -0800

    HBASE-23792 [Flakey Test] TestExportSnapshotNoCluster.testSnapshotWithRefsExportFileSystemState (#1124)
    
    1. Survive flakey rerunning by converting the static BeforeClass stuff
       into instance-level Before.
    2. Break the test method into two, one for running over each of the
       snapshot manifest versions.
    
    Signed-off-by: stack <stack@apache.org>

commit 299b6bebc5120dacf7a55cfba06de6d98fb973c0
Author: Mark Robert Miller <markrmiller@apache.org>
Date:   Tue Feb 4 16:38:56 2020 -0600

    HBASE-23783: Address tests writing and reading SSL/Security files in a common location. (#1116)
    
    This is causing me issues with parallel test runs.
    
    Also allow setting the surefire reports and temp directories via command line.
    
    Signed-off-by: stack <stack@apache.org>

commit 1cacf27d5c9746297922f5c2946fdbb3f0c431fe
Author: Nick Dimiduk <ndimiduk@apache.org>
Date:   Tue Feb 4 09:14:01 2020 -0800

    HBASE-23793 Increase maven heap allocation to 4G in Yetus personality (#1122)
    
    I saw this over on
    https://builds.apache.org/view/H-L/view/HBase/job/HBase%20Nightly/job/branch-2/2447/console. Looks
    like we need to bump the memory allocation for maven. I wonder if this
    is the underlying cause of HBASE-22470.
    
    ```
    6:38:47  ============================================================================
    16:38:47  ============================================================================
    16:38:47                                Finished build.
    16:38:47  ============================================================================
    16:38:47  ============================================================================
    16:38:47
    16:38:47
    Post stage
    [Pipeline] stash
    16:38:48  Warning: overwriting stash 'hadoop2-result'
    16:38:48  Stashed 1 file(s)
    [Pipeline] junit
    16:38:48  Recording test results
    16:38:54  Remote call on H2 failed
    Error when executing always post condition:
    java.io.IOException: Remote call on H2 failed
            at hudson.remoting.Channel.call(Channel.java:963)
            at hudson.FilePath.act(FilePath.java:1072)
            at hudson.FilePath.act(FilePath.java:1061)
            at hudson.tasks.junit.JUnitParser.parseResult(JUnitParser.java:114)
            at hudson.tasks.junit.JUnitResultArchiver.parse(JUnitResultArchiver.java:137)
            at hudson.tasks.junit.JUnitResultArchiver.parseAndAttach(JUnitResultArchiver.java:167)
            at hudson.tasks.junit.pipeline.JUnitResultsStepExecution.run(JUnitResultsStepExecution.java:52)
            at hudson.tasks.junit.pipeline.JUnitResultsStepExecution.run(JUnitResultsStepExecution.java:25)
            at org.jenkinsci.plugins.workflow.steps.SynchronousNonBlockingStepExecution.lambda$start$0(SynchronousNonBlockingStepExecution.java:47)
            at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
            at java.util.concurrent.FutureTask.run(FutureTask.java:266)
            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
            at java.lang.Thread.run(Thread.java:748)
    Caused by: java.lang.OutOfMemoryError: Java heap space
            at com.sun.org.apache.xerces.internal.util.XMLStringBuffer.append(XMLStringBuffer.java:208)
            at com.sun.org.apache.xerces.internal.impl.XMLEntityScanner.scanData(XMLEntityScanner.java:1515)
            at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanCDATASection(XMLDocumentFragmentScannerImpl.java:1654)
            at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:3014)
            at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:602)
            at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:112)
            at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:505)
            at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:842)
            at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:771)
            at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
            at com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1213)
            at com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:643)
            at org.dom4j.io.SAXReader.read(SAXReader.java:465)
            at org.dom4j.io.SAXReader.read(SAXReader.java:343)
            at hudson.tasks.junit.SuiteResult.parse(SuiteResult.java:178)
            at hudson.tasks.junit.TestResult.parse(TestResult.java:348)
            at hudson.tasks.junit.TestResult.parsePossiblyEmpty(TestResult.java:281)
            at hudson.tasks.junit.TestResult.parse(TestResult.java:206)
            at hudson.tasks.junit.TestResult.parse(TestResult.java:178)
            at hudson.tasks.junit.TestResult.<init>(TestResult.java:143)
            at hudson.tasks.junit.JUnitParser$ParseResultCallable.invoke(JUnitParser.java:146)
            at hudson.tasks.junit.JUnitParser$ParseResultCallable.invoke(JUnitParser.java:118)
            at hudson.FilePath$FileCallableWrapper.call(FilePath.java:3052)
            at hudson.remoting.UserRequest.perform(UserRequest.java:212)
            at hudson.remoting.UserRequest.perform(UserRequest.java:54)
            at hudson.remoting.Request$2.run(Request.java:369)
            at hudson.remoting.InterceptingExecutorService$1.call(InterceptingExecutorService.java:72)
            ... 4 more
    
    [Pipeline] }
    [Pipeline] // withEnv
    [Pipeline] }
    [Pipeline] // node
    [Pipeline] }
    [Pipeline] // stage
    [Pipeline] }
    16:38:54  Failed in branch yetus jdk8 hadoop2 checks
    ```
    
    Signed-off-by: stack <stack@apache.org>

commit bb14bdad6243a1063063e0fb97c8a34cac68acb1
Author: Duo Zhang <zhangduo@apache.org>
Date:   Tue Feb 4 10:14:27 2020 +0800

    HBASE-23782 Addendum fix error prone warning</pre></p>
  </body>
</html>
